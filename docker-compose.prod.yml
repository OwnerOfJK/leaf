services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: leaf-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${{project.POSTGRES_USER}}
      POSTGRES_PASSWORD: ${{project.POSTGRES_PASSWORD}}
      POSTGRES_DB: ${{project.POSTGRES_DB}}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - leaf-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${{project.POSTGRES_USER}} -d ${{project.POSTGRES_DB}}"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 3g
    mem_reservation: 2g
    shm_size: 256mb

  redis:
    image: redis:7-alpine
    container_name: leaf-redis
    restart: unless-stopped
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - leaf-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 768m
    mem_reservation: 512m

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: leaf-backend
    restart: unless-stopped
    environment:
      DATABASE_URL: ${{project.DATABASE_URL}}
      REDIS_URL: ${{project.REDIS_URL}}
      REDIS_SESSION_TTL: ${{project.REDIS_SESSION_TTL}}
      OPENAI_API_KEY: ${{project.OPENAI_API_KEY}}
      LANGFUSE_PUBLIC_KEY: ${{project.LANGFUSE_PUBLIC_KEY}}
      LANGFUSE_SECRET_KEY: ${{project.LANGFUSE_SECRET_KEY}}
      LANGFUSE_BASE_URL: ${{project.LANGFUSE_BASE_URL}}
      GOOGLE_BOOKS_API_KEY: ${{project.GOOGLE_BOOKS_API_KEY}}
      NYT_BOOKS_API_KEY: ${{project.NYT_BOOKS_API_KEY}}
      CELERY_BROKER_URL: ${{project.CELERY_BROKER_URL}}
      CELERY_RESULT_BACKEND: ${{project.CELERY_RESULT_BACKEND}}
      GUNICORN_WORKERS: ${{project.GUNICORN_WORKERS}}
      ENVIRONMENT: ${{project.ENVIRONMENT}}
      DEBUG: ${{project.DEBUG}}
      ALLOWED_ORIGINS: ${{project.ALLOWED_ORIGINS}}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - csv_uploads:/tmp/leaf_csv_uploads
    # Port 8000 NOT exposed - backend is internal only
    # Accessible to frontend via http://backend:8000 (Docker network)
    networks:
      - leaf-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    mem_limit: 1g
    mem_reservation: 512m

  celery-worker-1:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: leaf-celery-1
    restart: unless-stopped
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=2 --hostname=worker1@%h
    environment:
      DATABASE_URL: ${{project.DATABASE_URL}}
      REDIS_URL: ${{project.REDIS_URL}}
      REDIS_SESSION_TTL: ${{project.REDIS_SESSION_TTL}}
      OPENAI_API_KEY: ${{project.OPENAI_API_KEY}}
      LANGFUSE_PUBLIC_KEY: ${{project.LANGFUSE_PUBLIC_KEY}}
      LANGFUSE_SECRET_KEY: ${{project.LANGFUSE_SECRET_KEY}}
      LANGFUSE_BASE_URL: ${{project.LANGFUSE_BASE_URL}}
      GOOGLE_BOOKS_API_KEY: ${{project.GOOGLE_BOOKS_API_KEY}}
      NYT_BOOKS_API_KEY: ${{project.NYT_BOOKS_API_KEY}}
      CELERY_BROKER_URL: ${{project.CELERY_BROKER_URL}}
      CELERY_RESULT_BACKEND: ${{project.CELERY_RESULT_BACKEND}}
      ENVIRONMENT: ${{project.ENVIRONMENT}}
      DEBUG: ${{project.DEBUG}}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - csv_uploads:/tmp/leaf_csv_uploads
    networks:
      - leaf-network
    mem_limit: 512m
    mem_reservation: 256m

  celery-worker-2:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: leaf-celery
    restart: unless-stopped
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=2
    env_file:
      - ./backend/.env.prod
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - csv_uploads:/tmp/leaf_csv_uploads
    networks:
      - leaf-network
    mem_limit: 512m
    mem_reservation: 256m

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
    container_name: leaf-frontend
    restart: unless-stopped
    environment:
      BACKEND_INTERNAL_URL: ${{project.BACKEND_INTERNAL_URL}}
      NEXT_PUBLIC_API_URL: ${{project.NEXT_PUBLIC_API_URL}}
    depends_on:
      - backend
    ports:
      - "3000:3000"
    networks:
      - leaf-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    mem_limit: 512m
    mem_reservation: 256m

networks:
  leaf-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  csv_uploads:
