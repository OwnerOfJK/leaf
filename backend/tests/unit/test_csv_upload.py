"""CSV Upload Test Suite for Leaf Backend
"""

import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import pytest
import requests

BASE_URL = "http://localhost:8000"
# CSV file is in backend/data/ directory
CSV_PATH = Path(__file__).parent.parent.parent / "data" / "goodreads_library_export.csv"


# =============================================================================
# Test 1: Infrastructure & Prerequisites
# =============================================================================


def test_prerequisites():
    """Validate all prerequisites are met."""
    print("\n" + "=" * 70)
    print("TEST 1: Prerequisites Validation")
    print("=" * 70)

    failures = []

    # Check 1: Backend server
    try:
        response = requests.get(f"{BASE_URL}/")
        assert response.status_code == 200
        print("‚úì Backend server is running")
    except Exception as e:
        print(f"‚ùå Backend server not responding: {e}")
        print("   Run: uvicorn main:app --reload")
        failures.append(f"Backend server not responding: {e}")

    # Check 2: Database connection
    try:
        response = requests.get(f"{BASE_URL}/test/db")
        assert response.status_code == 200
        data = response.json()
        assert "books" in data.get("tables", [])
        print("‚úì Database connected with books table")
    except Exception as e:
        print(f"‚ùå Database check failed: {e}")
        failures.append(f"Database check failed: {e}")

    # Check 3: Redis connection
    try:
        response = requests.get(f"{BASE_URL}/test/redis")
        assert response.status_code == 200
        data = response.json()
        assert data.get("status") == "connected"
        print("‚úì Redis is connected")
    except Exception as e:
        print(f"‚ùå Redis check failed: {e}")
        print("   Run: docker-compose up -d redis")
        failures.append(f"Redis check failed: {e}")

    # Check 4: CSV file exists
    if CSV_PATH.exists():
        print(f"‚úì CSV file found: {CSV_PATH}")
    else:
        print(f"‚ùå CSV file not found: {CSV_PATH}")
        failures.append(f"CSV file not found: {CSV_PATH}")

    # Check 5: Celery worker (indirect check via task submission in main test)
    print("‚ö† Celery worker check will be validated during CSV processing")
    print("   Make sure to run: celery -A app.workers.celery_app worker --loglevel=info")

    if failures:
        pytest.fail(f"Prerequisites check failed:\n" + "\n".join(f"  - {f}" for f in failures))

    print(f"\n‚úÖ All prerequisites checks passed")


# =============================================================================
# Test 2: CSV Upload & Processing
# =============================================================================


def test_csv_upload_flow():
    """Test complete CSV upload and processing flow."""
    print("\n" + "=" * 70)
    print("TEST 2: CSV Upload & Async Processing")
    print("=" * 70)

    # Step 1: Create session with CSV upload
    print("\n1Ô∏è‚É£  Uploading CSV file...")

    with open(CSV_PATH, "rb") as csv_file:
        files = {"csv_file": ("goodreads_library_export.csv", csv_file, "text/csv")}
        data = {"initial_query": "I love fantasy and science fiction books"}

        response = requests.post(
            f"{BASE_URL}/api/sessions/create",
            files=files,
            data=data
        )

    assert response.status_code == 200, f"Failed to create session with CSV: {response.text}"

    session_data = response.json()
    session_id = session_data["session_id"]
    status = session_data["status"]

    print(f"  ‚úì Session created: {session_id}")
    print(f"  ‚úì Initial status: {status}")

    assert status == "processing_csv", f"Expected status 'processing_csv', got '{status}'"

    # Step 2: Poll status until processing completes
    print("\n2Ô∏è‚É£  Polling CSV processing status...")
    print("     (This may take several minutes depending on book count and API limits)")

    max_polls = 120  # 10 minutes max (5-second intervals)
    poll_interval = 5  # seconds
    poll_count = 0
    last_processed = 0

    while poll_count < max_polls:
        time.sleep(poll_interval)
        poll_count += 1

        status_response = requests.get(f"{BASE_URL}/api/sessions/{session_id}/status")

        assert status_response.status_code == 200, f"Status check failed: {status_response.text}"

        status_data = status_response.json()
        csv_status = status_data["csv_status"]
        books_processed = status_data.get("books_processed") or 0
        books_total = status_data.get("books_total") or 0
        new_books_added = status_data.get("new_books_added") or 0

        # Debug: Print status on first poll
        if poll_count == 1:
            print(f"     Initial status check: csv_status='{csv_status}'")
            print(f"     Response data: {status_data}")

        # Show progress if it changed
        if books_processed > last_processed:
            progress_pct = (books_processed / books_total * 100) if books_total > 0 else 0
            print(f"     Progress: {books_processed}/{books_total} books ({progress_pct:.1f}%) - {new_books_added} new books added")
            last_processed = books_processed

        # Check if completed
        if csv_status == "completed":
            print(f"\n  ‚úì CSV processing completed!")
            print(f"  ‚úì Total books: {books_total}")
            print(f"  ‚úì Books processed: {books_processed}")
            print(f"  ‚úì New books added: {new_books_added}")
            print(f"  ‚úì Existing books: {books_processed - new_books_added}")
            print(f"  ‚úì Time taken: {poll_count * poll_interval} seconds")
            break

        # Check if failed
        if csv_status == "failed":
            pytest.fail("CSV processing failed!")

    assert poll_count < max_polls, f"Timeout: CSV processing took longer than {max_polls * poll_interval} seconds"

    # Step 3: Verify session data contains user books
    print("\n3Ô∏è‚É£  Verifying session data...")

    # Note: Session data is stored in Redis, we'll verify via recommendations endpoint
    # which should use the books_from_csv data

    print("  ‚úì CSV processing pipeline completed successfully")


# =============================================================================
# Test 3: Data Integrity Verification
# =============================================================================


def test_data_integrity():
    """Verify that books were properly stored with all metadata fields."""
    print("\n" + "=" * 70)
    print("TEST 3: Data Integrity Verification")
    print("=" * 70)

    # This would require direct database queries
    # For now, we'll rely on the API flow to validate data integrity
    print("\n‚ö† Data integrity verification via direct DB queries")
    print("   Manual verification recommended:")
    print("   1. Check PostgreSQL books table for new entries")
    print("   2. Verify rich metadata fields are populated (categories, ratings, etc.)")
    print("   3. Verify embeddings are present (vector dimension 1536)")
    print("   4. Check data_source = 'google_books'")


# =============================================================================
# Test 4: Recommendations with CSV Data
# =============================================================================


def test_recommendations_with_csv():
    """Test that recommendations incorporate user's CSV book data."""
    print("\n" + "=" * 70)
    print("TEST 4: Recommendations with CSV Data")
    print("=" * 70)

    print("\n1Ô∏è‚É£  Creating session with CSV...")

    # Use a smaller subset for faster testing
    test_query = "Books similar to my favorites"

    with open(CSV_PATH, "rb") as csv_file:
        files = {"csv_file": ("test.csv", csv_file, "text/csv")}
        data = {"initial_query": test_query}

        response = requests.post(
            f"{BASE_URL}/api/sessions/create",
            files=files,
            data=data
        )

    assert response.status_code == 200, f"Failed to create session: {response.text}"

    session_id = response.json()["session_id"]
    print(f"  ‚úì Session created: {session_id}")

    # Wait for CSV processing
    print("\n2Ô∏è‚É£  Waiting for CSV processing...")
    max_wait = 600  # 10 minutes
    waited = 0

    while waited < max_wait:
        time.sleep(5)
        waited += 5

        status_response = requests.get(f"{BASE_URL}/api/sessions/{session_id}/status")
        csv_status = status_response.json()["csv_status"]

        if csv_status == "completed":
            print("  ‚úì CSV processing completed")
            break
        elif csv_status == "failed":
            pytest.fail("CSV processing failed")

    assert waited < max_wait, "Timeout waiting for CSV processing"

    # Submit follow-up answers
    print("\n3Ô∏è‚É£  Submitting follow-up answers...")
    answers_response = requests.post(
        f"{BASE_URL}/api/sessions/{session_id}/answers",
        json={
            "answers": {
                "question_1": "Fantasy with complex magic systems",
                "question_2": "Character-driven plots",
                "question_3": "Prefer series over standalone books"
            }
        }
    )

    assert answers_response.status_code == 200, f"Failed to submit answers: {answers_response.text}"

    answers_data = answers_response.json()
    csv_books_count = answers_data.get("csv_books_count", 0)
    print(f"  ‚úì Answers submitted")
    print(f"  ‚úì User's CSV contains {csv_books_count} books")

    # Get recommendations
    print("\n4Ô∏è‚É£  Generating recommendations...")
    rec_response = requests.get(f"{BASE_URL}/api/sessions/{session_id}/recommendations")

    assert rec_response.status_code == 200, f"Failed to get recommendations: {rec_response.text}"

    rec_data = rec_response.json()
    recommendations = rec_data["recommendations"]

    print(f"  ‚úì Received {len(recommendations)} recommendations")
    print("\nüìö Recommendations based on user's library:")

    for rec in recommendations:
        print(f"\n  [{rec['rank']}] {rec['book']['title']}")
        print(f"      Author: {rec['book']['author']}")
        print(f"      Score: {rec['confidence_score']}")
        print(f"      Why: {rec['explanation'][:150]}...")

    print("\n‚úÖ Recommendations with CSV data: PASSED")


# =============================================================================
# Main Test Runner
# =============================================================================


def main():
    """Run all CSV upload tests as a standalone script."""
    print("\n" + "üì§" * 35)
    print("LEAF BACKEND - CSV UPLOAD TEST SUITE")
    print("üì§" * 35)

    start_time = time.time()
    failed_tests = []

    # Run tests
    try:
        test_prerequisites()
    except (AssertionError, Exception) as e:
        print(f"\n‚ùå Prerequisites not met: {e}")
        failed_tests.append("prerequisites")
        print("\nPlease fix prerequisite issues before continuing.")
        sys.exit(1)

    try:
        test_csv_upload_flow()
    except (AssertionError, Exception) as e:
        print(f"\n‚ùå CSV upload test failed: {e}")
        failed_tests.append("csv_upload")

    try:
        test_data_integrity()
    except (AssertionError, Exception) as e:
        print(f"\n‚ùå Data integrity test failed: {e}")
        failed_tests.append("data_integrity")

    # Skip full recommendations test by default to save time
    print("\n‚ö† Skipping recommendations test to save time")
    print("   Run pytest with -k test_recommendations_with_csv to validate end-to-end flow")

    # Summary
    elapsed = time.time() - start_time
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)

    all_passed = len(failed_tests) == 0
    test_names = ["prerequisites", "csv_upload", "data_integrity"]
    for test_name in test_names:
        status = "‚ùå FAILED" if test_name in failed_tests else "‚úÖ PASSED"
        print(f"{test_name.upper():.<50} {status}")

    print(f"\nTotal time: {elapsed:.2f}s")

    if all_passed:
        print("\nüéâ ALL CSV UPLOAD TESTS PASSED!")
        print("\n" + "=" * 70)
        print("NEXT STEPS:")
        print("=" * 70)
        print("1. Verify books in PostgreSQL have rich metadata")
        print("2. Check embeddings are present (1536 dimensions)")
        print("3. Verify user_ratings are preserved in session data")
        print("4. Test recommendations flow with CSV data")
        print("5. Monitor Celery worker logs for any warnings")
        print("=" * 70)
    else:
        print("\n‚ùå SOME TESTS FAILED")
        sys.exit(1)


if __name__ == "__main__":
    main()
